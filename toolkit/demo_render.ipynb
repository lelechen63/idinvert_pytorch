{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render\n",
    "\n",
    "This demo shows how to render TU-models and multi-view models to color images and depth maps. Firstly, make sure the environment and sample data have been prepared following [README-toolkit](https://github.com/zhuhao-nju/facescape/blob/master/toolkit/README.md).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Render multi-view model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results saved to ./demo_output/\n"
     ]
    }
   ],
   "source": [
    "# render multi-view model\n",
    "import cv2, json, os\n",
    "import numpy as np\n",
    "import src.renderer as renderer\n",
    "\n",
    "cam_idx = 49\n",
    "mesh_dirname = \"../samples/sample_mview_data/4_anger.ply\"\n",
    "\n",
    "# read params to find a camera setting\n",
    "with open(\"../samples/sample_mview_data/4_anger/params.json\", 'r') as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "# extract KRt\n",
    "K = np.array(params['%d_K' % cam_idx])\n",
    "Rt = np.array(params['%d_Rt' % cam_idx])\n",
    "h_src = params['%d_height' % cam_idx]\n",
    "w_src = params['%d_width' % cam_idx]\n",
    "\n",
    "# scale K RT h w\n",
    "scale = 0.2\n",
    "h, w = int(h_src * scale), int(w_src * scale)\n",
    "K[:2,:] = K[:2,:] * scale\n",
    "\n",
    "# render\n",
    "rend_depth, rend_img = renderer.render_cvcam(mesh_dirname, K, Rt, rend_size=(h, w))\n",
    "\n",
    "# save image and depth\n",
    "os.makedirs(\"./demo_output/\", exist_ok = True)\n",
    "cv2.imwrite(\"./demo_output/mview_rend_view%d.jpg\" % cam_idx, rend_img)\n",
    "rend_depth_vis = rend_depth - np.min(rend_depth[rend_depth!=0])\n",
    "rend_depth_vis = (rend_depth_vis / np.max(rend_depth_vis) * 255).astype(np.uint8)\n",
    "cv2.imwrite(\"./demo_output/mview_depth_view%d.jpg\" % cam_idx, rend_depth_vis)\n",
    "print(\"results saved to ./demo_output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Render TU-model (base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results saved to ./demo_output/\n"
     ]
    }
   ],
   "source": [
    "# render multi-view model\n",
    "import cv2, json, os, trimesh\n",
    "import numpy as np\n",
    "import src.renderer as renderer\n",
    "\n",
    "# read tu base mesh\n",
    "tu_base_mesh = trimesh.load(\"../samples/sample_tu_model/1_neutral.obj\", process=False)\n",
    "\n",
    "# extract K Rt\n",
    "K = np.array([[2000, 0, 256],\n",
    "              [0, 2000, 256],\n",
    "              [0, 0, 1]], dtype=np.float64)\n",
    "\n",
    "Rt = np.array([[1, 0, 0, 0],\n",
    "               [0, -1, 0, 0],\n",
    "               [0, 0, -1, 1200]], dtype=np.float64)\n",
    "h, w = 512, 512\n",
    "tu_base_mesh.visual.material.diffuse = np.array([255, 255, 255, 255], dtype=np.uint8)\n",
    "\n",
    "\n",
    "# render texture image and depth\n",
    "rend_depth, rend_tex = renderer.render_cvcam(tu_base_mesh, K, Rt, rend_size=(h, w), \n",
    "                                             flat_shading=True)\n",
    "# render color image\n",
    "_, rend_color = renderer.render_cvcam(tu_base_mesh, K, Rt, rend_size=(h, w), \n",
    "                                      flat_shading=False)\n",
    "\n",
    "# render shade image\n",
    "tu_base_mesh.visual.material.image = np.ones((1, 1, 3), dtype=np.uint8)*255\n",
    "_, rend_shade = renderer.render_cvcam(tu_base_mesh, K, Rt, rend_size=(h, w), \n",
    "                                      flat_shading=False)\n",
    "\n",
    "# save all\n",
    "rend_depth_vis = rend_depth.copy()\n",
    "rend_depth_vis[rend_depth!=0] = rend_depth_vis[rend_depth!=0] - np.min(rend_depth[rend_depth!=0])\n",
    "rend_depth_vis = (rend_depth_vis / np.max(rend_depth_vis) * 255).astype(np.uint8)\n",
    "\n",
    "# save image and depth\n",
    "os.makedirs(\"./demo_output/\", exist_ok = True)\n",
    "cv2.imwrite(\"./demo_output/tu_tex.jpg\", rend_tex)\n",
    "cv2.imwrite(\"./demo_output/tu_color.jpg\", rend_color)\n",
    "cv2.imwrite(\"./demo_output/tu_shade.jpg\", rend_shade)\n",
    "rend_depth_vis = rend_depth - np.min(rend_depth[rend_depth!=0])\n",
    "rend_depth_vis = (rend_depth_vis / np.max(rend_depth_vis) * 255).astype(np.uint8)\n",
    "cv2.imwrite(\"./demo_output/tu_depth.jpg\", rend_depth_vis)\n",
    "print(\"results saved to ./demo_output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### (3) Render TU-model (base mesh + displacement map)\n",
    "\n",
    "Rendering with displacement map is not supported for many light-weight rendering libs.  Professional rendering softwares are required to render displacement map, like Blender, 3D Max, MAYA, ZBrush, etc.  ~~TODO: Blender is a open-source rendering software, here we provide a simple projects to rendering base mesh + displacement map in blender.~~\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:facescape]",
   "language": "python",
   "name": "conda-env-facescape-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
